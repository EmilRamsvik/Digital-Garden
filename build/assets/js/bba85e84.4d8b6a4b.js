"use strict";(self.webpackChunkdigital_garden=self.webpackChunkdigital_garden||[]).push([[74239],{99240:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>r,toc:()=>h});var t=s(85893),i=s(11151);const a={Pages:386,"Date Finished":"Sep 17, 2023",Author:"Chip Huen",tags:["books","machine-learning","data-science","data-engineering","#system-architecture\xa0","mlops","non-fiction"],finished:null,created:"2024-01-06T15:04",updated:"2024-01-06T15:04"},o="\ud83d\ude80 The Book in 3 Sentences",r={id:"Books/Book Reviews/Designing Machine Learning Systems",title:"\ud83d\ude80 The Book in 3 Sentences",description:"This book covers the fundamentals of designing machine learning systems. It goes through the entire lifecycle of a machine learning system and then discusses the ecosystem and the challenges and cases that need to be considered.",source:"@site/docs/Books/Book Reviews/Designing Machine Learning Systems.md",sourceDirName:"Books/Book Reviews",slug:"/Books/Book Reviews/Designing Machine Learning Systems",permalink:"/docs/Books/Book Reviews/Designing Machine Learning Systems",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Books/Book Reviews/Designing Machine Learning Systems.md",tags:[{label:"books",permalink:"/docs/tags/books"},{label:"machine-learning",permalink:"/docs/tags/machine-learning"},{label:"data-science",permalink:"/docs/tags/data-science"},{label:"data-engineering",permalink:"/docs/tags/data-engineering"},{label:"#system-architecture\xa0",permalink:"/docs/tags/system-architecture"},{label:"mlops",permalink:"/docs/tags/mlops"},{label:"non-fiction",permalink:"/docs/tags/non-fiction"}],version:"current",frontMatter:{Pages:386,"Date Finished":"Sep 17, 2023",Author:"Chip Huen",tags:["books","machine-learning","data-science","data-engineering","#system-architecture\xa0","mlops","non-fiction"],finished:null,created:"2024-01-06T15:04",updated:"2024-01-06T15:04"},sidebar:"gardenSidebar",previous:{title:"\ud83d\ude80 The Book in 3 Sentences",permalink:"/docs/Books/Book Reviews/Crucial Conversations Tools for Talking When Stakes are High"},next:{title:"\ud83d\ude80 The Book in 3 Sentences",permalink:"/docs/Books/Book Reviews/Economics in One Lesson"}},l={},h=[{value:"How I Discovered It",id:"how-i-discovered-it",level:2},{value:"Who Should Read It?",id:"who-should-read-it",level:2}];function d(e){const n={em:"em",h1:"h1",h2:"h2",li:"li",p:"p",ul:"ul",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"-the-book-in-3-sentences",children:"\ud83d\ude80 The Book in 3 Sentences"}),"\n",(0,t.jsx)(n.p,{children:"This book covers the fundamentals of designing machine learning systems. It goes through the entire lifecycle of a machine learning system and then discusses the ecosystem and the challenges and cases that need to be considered."}),"\n",(0,t.jsx)(n.h1,{id:"-impressions",children:"\ud83c\udfa8 Impressions"}),"\n",(0,t.jsx)(n.p,{children:"It is a good introduction to the entire machine learning lifecycle, made as an extension of notes from a lecture course from Stanford, it has the credibility of an academic book. It was interesting and quite easy to read."}),"\n",(0,t.jsx)(n.h2,{id:"how-i-discovered-it",children:"How I Discovered It"}),"\n",(0,t.jsx)(n.p,{children:"I discovered it as I wanted to become more proficient in reading about data science and machine learning and understanding the whole system."}),"\n",(0,t.jsx)(n.h2,{id:"who-should-read-it",children:"Who Should Read It?"}),"\n",(0,t.jsx)(n.p,{children:"Data scientists in small companies, preferably before you get too much experience."}),"\n",(0,t.jsx)(n.h1,{id:"\ufe0f-how-the-book-changed-me",children:"\u2618\ufe0f How the Book Changed Me"}),"\n",(0,t.jsx)(n.h1,{id:"\ufe0f-my-top--quotes",children:"\u270d\ufe0f My Top  Quotes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"This book is for anyone who wants to leverage ML to solve real-world problems. ML in this book refers to both deep learning and classical algorithms, with a leaning toward ML systems at scale, such as those seen at medium to large enterprises and fast-growing startups."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"In November 2016, Google announced that it had incorporated its multilingual neural machine translation system into Google Translate, marking one of the first success stories of deep artificial neural networks in production at scale. According to Google, with this update, the quality of translation improved more in a single leap than they had seen in the previous 10 years combined."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Machine learning is an approach to learning complex patterns from existing data and using these patterns to make predictions on unseen data."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"In English, \u201cpredict\u201d means \u201cestimate a value in the future.\u201d"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"ML is especially suitable when the cost of a wrong prediction is low. For example, one of the biggest use cases of ML today is in recommender systems because with recommender systems, a bad recommendation is usually forgiving\u2014the user just won\u2019t click on the recommendation."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Deciding how much to charge for your product or service is probably one of the hardest business decisions; why not let ML do it for you? Price optimization is the process of estimating a price at a certain time period to maximize a defined objective function, such as the company\u2019s margin, revenue, or growth rate. ML-based pricing optimization is most suitable for cases with a large number of transactions where demand fluctuates and consumers are willing to pay a dynamic price\u2014"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Acquiring a new user is expensive. As of 2019, the average cost for an app to acquire a user who\u2019ll make an in-app purchase is $86.61.9 The acquisition cost for Lyft is estimated at $158/rider. This cost is so much higher for enterprise customers. Customer acquisition cost is hailed by investors as a startup killer."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Typically, the percentiles you\u2019ll want to look at are p90, p95, and p99. The 90th percentile (p90) for the 10 requests above is 3,000 ms, which is an outlier."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"For example, on the Amazon website, the customers with the slowest requests are often those who have the most data on their accounts because they have made many purchases\u2014that is, they\u2019re the most valuable customers."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"In 2019, \u201cBerkeley researchers found that both face-to-face and online lenders rejected a total of 1.3 million creditworthy Black and Latino applicants between 2008 and 2015.\u201d When the researchers \u201cused the income and credit scores of the rejected applications but deleted the race identifiers, the mortgage application was accepted.\u201d"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"That\u2019s an excellent idea. In fact, ML production would be a much better place if ML experts were better software engineers."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Bidirectional Encoder Representations from Transformers (BERT) paper first came out, people were talking about how BERT was too big, too complex, and too slow to be practical."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"While most companies want to convince you otherwise, the sole purpose of businesses, according to the Nobel-winning economist Milton Friedman, is to maximize profits for shareholders."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The ultimate goal of any project within a business is, therefore, to increase profits, either directly or indirectly: directly such as increasing sales (conversion rates) and cutting costs;"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The specified requirements for an ML system vary from use case to use case. However, most systems should have these four characteristics: reliability, scalability, maintainability, and adaptability."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The system should continue to perform the correct function at the desired level of performance even in the face of adversity (hardware or software faults, and even human error)."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Whichever way your system grows, there should be reasonable ways of dealing with that growth. When talking about scalability most people think of resource scaling, which consists of up-scaling (expanding the resources to handle growth) and down-scaling (reducing the resources when not needed)."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"To adapt to shifting data distributions and business requirements, the system should have some capacity for both discovering aspects for performance improvement and allowing updates without service interruption."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"*Step 1. Project scoping A project starts with scoping the project, laying out goals, objectives, and constraints. Stakeholders should be identified and involved. Resources should be estimated and allocated. We already discussed different stakeholders and some of the foci for ML projects in production in Chapter\xa01. We also already discussed how to scope an ML project in the context of a business earlier in this chapter. We\u2019ll discuss how to organize teams to ensure the success of an ML project in Chapter\xa011."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Step 2. Data engineering A vast majority of ML models today learn from data, so developing ML models starts with engineering data. In Chapter\xa03, we\u2019ll discuss the fundamentals of data engineering, which covers handling data from different sources and formats. With access to raw data, we\u2019ll want to curate training data out of it by sampling and generating labels, which is discussed in Chapter\xa04."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Step 3. ML model development With the initial set of training data, we\u2019ll need to extract features and develop initial models leveraging these features. This is the stage that requires the most ML knowledge and is most often covered in ML courses. In Chapter\xa05, we\u2019ll discuss feature engineering. In Chapter\xa06, we\u2019ll discuss model selection, training, and evaluation"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Step 4. Deployment After a model is developed, it needs to be made accessible to users. Developing an ML system is like writing\u2014you will never reach the point when your system is done. But you do reach the point when you have to put your system out there. We\u2019ll discuss different ways to deploy an ML model in Chapter\xa07."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Step 5. Monitoring and continual learning Once in production, models need to be monitored for performance decay and maintained to be adaptive to changing environments and changing requirements. This step will be discussed in Chapters 8 and 9."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Step 6. Business analysis Model performance needs to be evaluated against business goals and analyzed to generate business insights. These insights can then be used to eliminate unproductive projects or scope out new projects. This step is closely related to the first step."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"An ML problem is defined by inputs, outputs, and the objective function that guides the learning process\u2014"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Classification models classify inputs into different categories. For example, you want to classify each email to be either spam or not spam. Regression models output a continuous value. An example is a house prediction model that outputs the price of a given house."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"In my experience, ML models typically need at least 100 examples for each class to learn to classify that class."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Out of all task types, multilabel classification is usually the one that I\u2019ve seen companies having the most problems with. Multilabel means that the number of classes an example can have varies from example to example."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Without data, there\u2019s no data science."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Note that objective functions are mathematical functions, which are different from the business and ML objectives we discussed earlier in this chapter."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"*If you want to learn more about data engineering from a systems perspective, I recommend Martin Kleppmann\u2019s excellent book Designing Data-Intensive Applications"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"If it\u2019s even remotely possible for users to input the wrong data, they are going to do it."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"First-party data is the data that your company already collects about your users or customers. Second-party data is the data collected by another company on their own customers that they make available to you, though you\u2019ll probably have to pay for it. Third-party data companies collect data on the public who aren\u2019t their direct customers."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Overall, row-major formats are better when you have to do a lot of writes, whereas column-major ones are better when you have to do a lot of column-based reads."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"AWS recommends using the Parquet format because \u201cthe Parquet format is up to 2x faster to unload and consumes up to 6x less storage in Amazon S3, compared to text formats.\u201d"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The most important thing to note about SQL is that it\u2019s a declarative language, as opposed to Python, which is an imperative language. In the imperative paradigm, you specify the steps needed for an action and the computer executes these steps to return the outputs. In the declarative paradigm, you specify the outputs you want, and the computer figures out the steps needed to get you the queried outputs."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"In the early days of the relational data model, data was mostly structured. When data is extracted from different sources, it\u2019s first transformed into the desired format before being loaded into the target destination such as a database or a data warehouse. This process is called ETL, which stands for extract, transform, and load."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The two most common types of real-time transports are pubsub, which is short for publish-subscribe, and message queue. In the pubsub model, any service can publish to different topics in a real-time transport, and any service that subscribes to a topic can read all the events in that topic. The services that produce data don\u2019t care about what services consume their data."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Once your data arrives in data storage engines like databases, data lakes, or data warehouses, it becomes historical data."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Structured data means that the code that writes the data has to assume the structure. Unstructured data means that the code that reads the data has to assume the structure."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"\u201cInteresting\u201d in production usually means catastrophic, such as a crash or when your cloud bill hits an astronomical amount."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"As of November 2021, AWS S3 Standard, the storage option that allows you to access your data with the latency of milliseconds, costs about five times more per GB than S3 Glacier, the storage option that allows you to retrieve your data with a latency from between 1 minute to 12 hours."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"An ML engineer once mentioned to me that his team only used users\u2019 historical product browsing and purchases to make recommendations on what they might like to see next. I responded: \u201cSo you don\u2019t use personal data at all?\u201d He looked at me, confused. \u201cIf you meant demographic data like users\u2019 age, location, then no, we don\u2019t. But I\u2019d say that a person\u2019s browsing and purchasing activities are extremely personal.\u201d"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Convenience sampling Samples of data are selected based on their availability. This sampling method is popular because, well, it\u2019s convenient."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Snowball sampling Future samples are selected based on existing samples. For example, to scrape legitimate Twitter accounts without having access to Twitter databases, you start with a small number of accounts, then you scrape all the accounts they follow, and so on. Judgment sampling Experts decide what samples to include. Quota sampling You select samples based on quotas for certain slices of data without any randomization. For example, when doing a survey, you might want 100 responses from each of the age groups: under 30 years old, between 30 and 60 years old, and above 60 years old, regardless of the actual age distribution."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The higher the level of domain expertise required, the higher the potential for annotating disagreement."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"It\u2019s good practice to keep track of the origin of each of your data samples as well as its labels, a technique known as data lineage. Data lineage helps you both flag potential biases in your data and debug your models."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The canonical example of tasks with natural labels is recommender systems. The goal of a recommender system is to recommend to users items relevant to them."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"If hand labeling is so problematic, what if we don\u2019t use hand labels altogether? One approach that has gained popularity is weak supervision. One of the most popular open source tools for weak supervision is Snorkel, developed at the Stanford AI Lab."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:'Libraries like Snorkel are built around the concept of a labeling function (LF): a function that encodes heuristics. The preceding heuristics can be expressed by the following function: def labeling_function(note): if "pneumonia" in note: return "EMERGENT" LFs can encode many different types of heuristics. Here are some of them: Keyword heuristic Such as the preceding example Regular expressions Such as if the note matches or fails to match a certain regular expression Database lookup Such as if the note contains the disease listed in the dangerous disease list The outputs of other models Such as if an existing system classifies this as EMERGENT'})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Because LFs encode heuristics, and heuristics are noisy, labels produced by LFs are noisy. Multiple LFs might apply to the same data examples, and they might give conflicting labels."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"A semi-supervision method that has gained popularity in recent years is the perturbation-based method. It\u2019s based on the assumption that small perturbations to a sample shouldn\u2019t change its label. So you apply small perturbations to your training instances to obtain new training instances. The perturbations might be applied directly to the samples (e.g., adding white noise to images) or to their representations (e.g., adding small random values to embeddings of words)."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Active learning is a method for improving the efficiency of data labels. The hope here is that ML models can achieve greater accuracy with fewer training labels if they can choose which data samples to learn from."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"According to Talos Intelligence, as of May 2021, nearly 85% of all emails are spam."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Ding et al. showed that very deep neural networks\u2014with \u201cvery deep\u201d meaning over 10 layers back in 2017\u2014performed much better on imbalanced data than shallower neural networks."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"One such technique is two-phase learning. You first train your model on the resampled data. This resampled data can be achieved by randomly undersampling large classes until each class has only N instances. You then fine-tune your model on the original data."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Su et al. showed that 67.97% of the natural images in the Kaggle CIFAR-10 test dataset and 16.04% of the ImageNet test images can be misclassified by changing just one pixel"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Using deceptive data to trick a neural network into making wrong predictions is called adversarial attacks. Adding noise to samples is a common technique to create adversarial samples. The success of adversarial attacks is especially exaggerated as the resolution of images increases. Adding noisy samples to training data can help models recognize the weak spots in their learned decision boundary and improve their performance."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The promise of deep learning is that we won\u2019t have to handcraft features. For this reason, deep learning is sometimes called feature learning."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Not all types of missing values are equal."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"In my experience, how well a person handles missing values for a given dataset during interviews strongly correlates with how well they will do in their day-to-day jobs."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Missing not at random (MNAR) This is when the reason a value is missing is because of the true value itself. In this example, we might notice that some respondents didn\u2019t disclose their income. Upon investigation it may turn out that the income of respondents who failed to report tends to be higher than that of those who did disclose."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Missing at random (MAR) This is when the reason a value is missing is not due to the value itself, but due to another observed variable. In this example, we might notice that age values are often missing for respondents of the gender \u201cA,\u201d which might be because the people of gender A in this survey don\u2019t like disclosing their age."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Missing completely at random (MCAR) This is when there\u2019s no pattern in when the value is missing."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"When I ask candidates about how to handle missing values during interviews, many tend to prefer deletion, not because it\u2019s a better method, but because it\u2019s easier to do."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Another way to delete is row deletion: if a sample has missing value(s), just remove that sample. This method can work when the missing values are completely at random (MCAR) and the number of examples with missing values is small, such as less than 0.1%. You don\u2019t want to do row deletion if that means 10% of your data samples are removed."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Before inputting features into models, it\u2019s important to scale them to be similar ranges. This process is called feature scaling. This is one of the simplest things you can do that often results in a performance boost for your model. Neglecting to do so can cause your model to make gibberish predictions, especially with classical algorithms like gradient-boosted trees and logistic regression."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"In practice, ML models tend to struggle with features that follow a skewed distribution. To help mitigate the skewness, a technique commonly used is log transformation: apply the log function to your feature."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"One solution to this problem is the hashing trick, popularized by the package Vowpal Wabbit developed at Microsoft. The gist of this trick is that you use a hash function to generate a hashed value of each category. The hashed value will become the index of that category. Because you can specify the hash space, you can fix the number of encoded values for a feature in advance, without having to know how many categories there will be. For example, if you choose a hash space of 18 bits, which corresponds to 218 = 262,144 possible hashed values, all the categories, even the ones that your model has never seen before, will be encoded by an index between 0 and 262,143."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Because it\u2019s a trick, it\u2019s often considered hacky by academics and excluded from ML curricula. But its wide adoption in the industry is a testimonial to how effective the trick is. It\u2019s essential to Vowpal Wabbit and it\u2019s part of the frameworks of scikit-learn, TensorFlow, and gensim."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Feature crossing is the technique to combine two or more features to generate new features. This technique is useful to model the nonlinear relationships between features."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Both of these are examples of data leakage. Data leakage refers to the phenomenon when a form of the label \u201cleaks\u201d into the set of features used for making predictions, and this same information is not available during inference."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Data leakage refers to the phenomenon when a form of the label \u201cleaks\u201d into the set of features used for making predictions, and this same information is not available during inference."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"When measuring feature importance for a click-through rate prediction model, the ads team at Facebook found out that the top 10 features are responsible for about half of the model\u2019s total feature importance, whereas the last 300 features contribute less than 1% feature importance, as shown"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Zen of Python states that \u201csimple is better than complex,\u201d and this principle is applicable to ML as well."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Simplicity serves three purposes. First, simpler models are easier to deploy, and deploying your model early allows you to validate that your prediction pipeline is consistent with your training pipeline. Second, starting with something simple and adding more complex components step-by-step makes it easier to understand your model and debug it. Third, the simplest model serves as a baseline to which you can compare your more complex models."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The more components a model has, the more things that can go wrong, and the harder it is to figure out which goes wrong."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Overfit a single batch After you have a simple implementation of your model, try to overfit a small amount of training data and run evaluation on the same data to make sure that it gets to the smallest possible loss. If it\u2019s for image recognition, overfit on 10 images and see if you can get the accuracy to be 100%, or if it\u2019s for machine translation, overfit on 100 sentence pairs and see if you can get to a BLEU score of near 100. If it can\u2019t overfit a small amount of data, there might be something wrong with your implementation."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Evaluation metrics, by themselves, mean little. When evaluating your model, it\u2019s essential to know the baseline you\u2019re evaluating it against. The exact baselines should vary from one use case to another, but here are the five baselines that might be useful across use cases:"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Random baseline If our model just predicts at random, what\u2019s the expected performance? The predictions are generated at random following a specific distribution, which can be the uniform distribution or the task\u2019s label distribution."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Simple heuristic Forget ML. If you just make predictions based on simple heuristics, what performance would you expect? For example, if you want to build a ranking system to rank items on a user\u2019s newsfeed with the goal of getting that user to spend more time on the newsfeed, how much time would a user spend if you just rank all the items in reverse chronological order, showing the latest one first?"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Zero rule baseline The zero rule baseline is a special case of the simple heuristic baseline when your baseline model always predicts the most common class."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Andrew Ng has a great lecture where he explains that if a learning algorithm suffers from high bias, getting more training data by itself won\u2019t help much. Whereas if a learning algorithm suffers from high variance, getting more training data is likely to help."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The process of generating predictions is called inference. We\u2019ll continue with where the"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"For example, the compute primitive of CPUs used to be a number (scalar) and the compute primitive of GPUs used to be a one-dimensional vector, whereas the compute primitive of TPUs is a two-dimensional vector (tensor)."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"For readers interested in learning how to make ML systems reliable from the software engineering perspective, I highly recommend the book Reliable Machine Learning,"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"In the section \u201cNatural Labels\u201d, we discussed a feedback loop as the time it takes from when a prediction is shown until the time feedback on the prediction is provided."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"A degenerate feedback loop can happen when the predictions themselves influence the feedback, which, in turn, influences the next iteration of the model. More formally, a degenerate feedback loop is created when a system\u2019s outputs are used to generate the system\u2019s future inputs, which, in turn, influence the system\u2019s future outputs."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"To make this concrete, imagine you build a system to recommend to users songs that they might like. The songs that are ranked high by the system are shown first to users. Because they are shown first, users click on them more, which makes the system more confident that these recommendations are good."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"This type of scenario is incredibly common in production, and it\u2019s heavily researched. It goes by many different names, including \u201cexposure bias,\u201d \u201cpopularity bias,\u201d \u201cfilter bubbles,\u201d and sometimes \u201cecho chambers.\u201d"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"While data distribution shift is often used interchangeably with concept drift and covariate shift and occasionally label shift, these are three distinct subtypes of data shift."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Covariate shift When P(X) changes but P(Y|X) remains the same. This refers to the first decomposition of the joint distribution. Label shift When P(Y) changes but P(X|Y) remains the same. This refers to the second decomposition of the joint distribution. Concept drift When P(Y|X) changes but P(X) remains the same. This refers to the first decomposition of the joint distribution."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The first step of feature monitoring is feature validation: ensuring that your features follow an expected schema. The expected schemas are usually generated from training data or from common sense. If these expectations are violated in production, there might be a shift in the underlying distribution."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Excessive metrics on a dashboard can also be counterproductive, a phenomenon known as dashboard rot. It\u2019s important to pick the right metrics or abstract out lower-level metrics to compute higher-level signals that make better sense for your specific tasks."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"To understand failures of ML systems, we differentiated between two types of failures: software systems failures (failures that also happen to non-ML systems) and ML-specific failures. Even though the majority of ML failures today are non-ML-specific, as tooling and infrastructure around MLOps matures, this might change."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"First, if your model is a neural network, learning with every incoming sample makes it susceptible to catastrophic forgetting. Catastrophic forgetting refers to the tendency of a neural network to completely and abruptly forget previously learned information upon learning new information."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The updated model shouldn\u2019t be deployed until it\u2019s been evaluated. This means that you shouldn\u2019t make changes to the existing model directly. Instead, you create a replica of the existing model and update this replica on new data, and only replace the existing model with the updated replica if the updated replica proves to be better. The existing model is called the champion model, and the updated replica, the challenger."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Most companies do stateless retraining\u2014the model is trained from scratch each time. Continual learning means also allowing stateful training\u2014the model continues training on new data."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Most companies do stateless retraining\u2014the model is trained from scratch each time. Continual learning means also allowing stateful training\u2014the model continues training on new data.2 Stateful training is also known as fine-tuning or incremental learning."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"One beautiful property that is often overlooked is that with stateful training, it might be possible to avoid storing data altogether."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Model iteration A new feature is added to an existing model architecture or the model architecture is changed. Data iteration The model architecture and features remain the same, but you refresh this model with new data."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The first use case of continual learning is to combat data distribution shifts, especially when the shifts happen suddenly. Imagine you\u2019re building a model to determine the prices for a ride-sharing service like Lyft.6 Historically, the ride demand on a Thursday evening in this particular neighborhood is slow, so the model predicts low ride prices, which makes it less appealing for drivers to get on the road. However, on this Thursday evening, there\u2019s a big event in the neighborhood, and suddenly the ride demand surges."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"TikTok, for example, has successfully applied continual learning to adapt their recommender system to each user within minutes. You download the app and, after a few videos, TikTok\u2019s algorithms are able to predict with high accuracy what you want to watch next. I don\u2019t think everyone should try to build something as addictive as TikTok, but it\u2019s proof that continual learning can unlock powerful predictive potential."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The best candidates for continual learning are tasks where you can get natural labels with short feedback loops. Examples of these tasks are dynamic pricing (based on estimated demand and availability),"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"It\u2019s much easier to adapt models like neural networks than matrix-based and tree-based models to the continual learning paradigm."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"The second factor is the availability and accessibility of your data. Do you need to gather data yourself into your data warehouse? Will you have to join data from multiple organizations? Do you need to extract a lot of features from scratch? Will you also need to label your data? The more questions you answer yes to, the more time it will take to set up this script. Stefan Krawczyk, ML/data platform manager at Stitch Fix, commented that he suspects most people\u2019s time might be spent here."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Contextual bandits are also called \u201cone-shot\u201d reinforcement learning problems. In reinforcement learning, you might need to take a series of actions before seeing the rewards. In contextual bandits, you can get bandit feedback right away after an action\u2014"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"You have time to set up only one piece of infrastructure well, make it the development environment for data scientists.\u201d Because the dev environment is where engineers work, improvements in the dev environment translate directly into improvements in engineering productivity."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"\u201cBeyond Interactive: Notebook Innovation at Netflix,\u201d Netflix included a list of infrastructure tools that can be used to make notebooks even more powerful. The list includes: Papermill For spawning multiple notebooks with different parameter sets\u2014such as when you want to run different experiments with different sets of parameters and execute them concurrently. It can also help summarize metrics from a collection of notebooks. Commuter A notebook hub for viewing, finding, and sharing notebooks within an organization."})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"According to Frederick P. Brooks, \u201cWhat one programmer can do in one month, two programmers can do in two months.\u201d"})}),"\n"]}),"\n"]})]})}function c(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},11151:(e,n,s)=>{s.d(n,{Z:()=>r,a:()=>o});var t=s(67294);const i={},a=t.createContext(i);function o(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);